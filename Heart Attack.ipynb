{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b885adf3",
   "metadata": {},
   "source": [
    " # Importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix , classification_report  , accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d090abd",
   "metadata": {},
   "source": [
    "# Reading the data in pandas and preview it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4dda3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
      "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
      "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
      "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
      "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
      "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
      "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
      "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
      "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
      "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
      "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
      "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
      "\n",
      "     caa  thall  output  \n",
      "0      0      1       1  \n",
      "1      0      2       1  \n",
      "2      0      2       1  \n",
      "3      0      2       1  \n",
      "4      0      2       1  \n",
      "..   ...    ...     ...  \n",
      "298    0      3       0  \n",
      "299    0      3       0  \n",
      "300    2      3       0  \n",
      "301    1      3       0  \n",
      "302    1      2       0  \n",
      "\n",
      "[303 rows x 14 columns]>\n",
      "<bound method DataFrame.value_counts of      age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
      "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
      "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
      "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
      "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
      "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
      "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
      "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
      "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
      "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
      "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
      "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
      "\n",
      "     caa  thall  output  \n",
      "0      0      1       1  \n",
      "1      0      2       1  \n",
      "2      0      2       1  \n",
      "3      0      2       1  \n",
      "4      0      2       1  \n",
      "..   ...    ...     ...  \n",
      "298    0      3       0  \n",
      "299    0      3       0  \n",
      "300    2      3       0  \n",
      "301    1      3       0  \n",
      "302    1      2       0  \n",
      "\n",
      "[303 rows x 14 columns]>\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"F:\\DATA\\MAIN\\/Heart Attack Risk.csv\")\n",
    "print(df.head)\n",
    "print(df.value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab92b4f",
   "metadata": {},
   "source": [
    "# Targeting x , y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41997170",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['output'] ,  axis= 1 )\n",
    "y=df['output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2defaf99",
   "metadata": {},
   "source": [
    "# test and train split (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1dd80c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msk=np.random.rand(len(df)) < 0.8\n",
    "\n",
    "train_x = x[msk]\n",
    "test_x = x[~msk]\n",
    "train_y = y[msk]\n",
    "test_y = y[~msk]         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b7fce",
   "metadata": {},
   "source": [
    "# modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd36c4",
   "metadata": {},
   "source": [
    "# checking the resault with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8018d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: liblinear, Accuracy: 0.8524590163934426\n",
      "Solver: sag, Accuracy: 0.7213114754098361\n",
      "Solver: saga, Accuracy: 0.6721311475409836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\korosh king\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\korosh king\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: lbfgs, Accuracy: 0.8524590163934426\n",
      "Solver: newton-cholesky, Accuracy: 0.8524590163934426\n",
      "Solver: newton-cg, Accuracy: 0.8524590163934426\n",
      "Best Solver: liblinear, Best Accuracy: 0.8524590163934426\n",
      "Confusion Matrix:\n",
      " [[23  5]\n",
      " [ 4 29]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR=LogisticRegression(C=1 , solver='liblinear').fit(train_x , train_y)\n",
    "solvers = ['liblinear', 'sag', 'saga', 'lbfgs', 'newton-cholesky', 'newton-cg']\n",
    "best_solver = ''\n",
    "best_accuracy = 0\n",
    "\n",
    "for solver in solvers:\n",
    "        model = LogisticRegression(solver=solver, max_iter=1000).fit(train_x, train_y)\n",
    "        test_y_ = model.predict(test_x)\n",
    "        accuracy = accuracy_score(test_y, test_y_)\n",
    "        \n",
    "        print(f\"Solver: {solver}, Accuracy: {accuracy}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_solver = solver\n",
    "\n",
    "\n",
    "print(f\"Best Solver: {best_solver}, Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(test_y, test_y_)\n",
    "print(\"Confusion Matrix:\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ac7d5",
   "metadata": {},
   "source": [
    " -the accuracy of LR is very good and the FN is 5 which is acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e068a5",
   "metadata": {},
   "source": [
    "# checking the resault with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00a85180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: sigmoid, Accuracy: 0.5245901639344263\n",
      "Kernel: poly, Accuracy: 0.639344262295082\n",
      "Kernel: rbf, Accuracy: 0.6229508196721312\n",
      "Kernel: precomputed failed\n",
      "Kernel: linear, Accuracy: 0.6065573770491803\n",
      "Best Kernel: poly, Best Accuracy: 0.639344262295082\n",
      "Confusion Matrix: [[13 15]\n",
      " [ 9 24]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\korosh king\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# لیست کرنل‌ها\n",
    "kernels = ['sigmoid', 'poly', 'rbf', 'precomputed', 'linear']\n",
    "best_kernel = ''\n",
    "best_accuracy = 0\n",
    "\n",
    "# حلقه برای تست کرنل‌ها\n",
    "for kernel in kernels:\n",
    "    try:\n",
    "        model = SVC(kernel=kernel, max_iter=1000).fit(train_x, train_y)\n",
    "        test_y_ = model.predict(test_x)\n",
    "        accuracy = accuracy_score(test_y, test_y_)\n",
    "        \n",
    "        # چاپ دقت برای هر کرنل\n",
    "        print(f\"Kernel: {kernel}, Accuracy: {accuracy}\")\n",
    "        \n",
    "        # به‌روزرسانی بهترین کرنل و دقت\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_kernel = kernel\n",
    "    except:\n",
    "        print(f\"Kernel: {kernel} failed\")\n",
    "\n",
    "print(f\"Best Kernel: {best_kernel}, Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(test_y, test_y_)\n",
    "print(\"Confusion Matrix:\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa78b6a",
   "metadata": {},
   "source": [
    "-so we undrestand that SVM is not a proper model for this data and also FN is to high "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd72c0",
   "metadata": {},
   "source": [
    "# Now Lets try the resault with DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ac554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: gini, Accuracy: 0.7704918032786885\n",
      "Criterion: entropy, Accuracy: 0.819672131147541\n",
      "Criterion: log_loss, Accuracy: 0.819672131147541\n",
      "\n",
      "Best Criterion: entropy, Best Accuracy: 0.819672131147541\n",
      "Confusion Matrix: [[23  5]\n",
      " [ 6 27]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "best_criterion = ''\n",
    "best_accuracy = 0\n",
    "\n",
    "for criterion in criteria:\n",
    "    try:\n",
    "        dTree = DecisionTreeClassifier(criterion=criterion, max_depth=4).fit(train_x, train_y)\n",
    "        test_y_ = dTree.predict(test_x)\n",
    "        accuracy = accuracy_score(test_y, test_y_)\n",
    "        \n",
    "        print(f\"Criterion: {criterion}, Accuracy: {accuracy}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_criterion = criterion\n",
    "    except:\n",
    "        print(f\"Criterion: {criterion} failed\")\n",
    "\n",
    "print(f\"Best Criterion: {best_criterion}, Best Accuracy: {best_accuracy}\")\n",
    "conf_matrix = confusion_matrix(test_y, test_y_)\n",
    "print(\"Confusion Matrix:\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3accd3df",
   "metadata": {},
   "source": [
    "- - ALso the accuracy of DTree is very good and the FN is 5 again which is acceptable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d999d",
   "metadata": {},
   "source": [
    "# Based on this program, we found that the best classifier models are Decision Tree (DTree) and Logistic Regression (LR). Additionally, by adjusting the parameters, I realized that the best criterion for DTree is entropy, and for Logistic Regression, the best solver is liblinear, both achieving approximately 85% accuracy.But SVM is not a correct model for this data frame :)) .\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
